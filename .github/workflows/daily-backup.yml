name: Daily Full MERN Backup

on:
  schedule:
    - cron: '0 2 * * *'  # Every day at 2 AM UTC
  workflow_dispatch:  # Manual trigger

jobs:
  backup:
    runs-on: ubuntu-latest
    env:
      MONGODB_URI: ${{ secrets.MONGODB_URI }}
      REDIS_URL: ${{ secrets.REDIS_URL }}
      CLOUDINARY_CLOUD_NAME: ${{ secrets.CLOUDINARY_CLOUD_NAME }}
      CLOUDINARY_API_KEY: ${{ secrets.CLOUDINARY_API_KEY }}
      CLOUDINARY_API_SECRET: ${{ secrets.CLOUDINARY_API_SECRET }}
      BACKEND_ENV: ${{ secrets.BACKEND_ENV }}
      GDRIVE_FOLDER_ID: ${{ secrets.GDRIVE_FOLDER_ID }}
      SERVICE_ACCOUNT_JSON: ${{ secrets.SERVICE_ACCOUNT_JSON }}

    steps:
      - name: Checkout Backend Repo
        uses: actions/checkout@v4
        with:
          path: backend

      - name: Checkout Frontend Repo
        uses: actions/checkout@v4
        with:
          repository: r0o7-73rm1n41/dme-frontend
          path: frontend

      - name: Install Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y gnupg curl
          curl -fsSL https://www.mongodb.org/static/pgp/server-7.0.asc | \
             sudo gpg -o /usr/share/keyrings/mongodb-server-7.0.gpg \
             --dearmor
          echo "deb [ arch=amd64,arm64 signed-by=/usr/share/keyrings/mongodb-server-7.0.gpg ] https://repo.mongodb.org/apt/ubuntu jammy/mongodb-org/7.0 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-7.0.list
          sudo apt-get update
          sudo apt-get install -y zip wget curl mongodb-org-tools redis-tools nodejs npm

      - name: Create Backup Directory
        run: mkdir backup

      # --- MongoDB Backup ---
      - name: MongoDB Dump
        run: |
          TIMESTAMP=$(date +'%F_%H-%M')
          mongodump --uri="$MONGODB_URI" --archive=backup/mongodb_$TIMESTAMP.gz --gzip

      # --- Redis Backup (Upstash) ---
      - name: Redis Backup
        run: |
          TIMESTAMP=$(date +'%F_%H-%M')
          redis-cli -u $REDIS_URL --rdb backup/redis_$TIMESTAMP.rdb || echo "Redis backup failed - Upstash may not support direct RDB dumps"

      # --- Cloudinary Backup ---
      - name: Cloudinary Backup
        run: |
          TIMESTAMP=$(date +'%F_%H-%M')
          npm install cloudinary
          mkdir -p backup/cloudinary
          node -e "
            const cloudinary = require('cloudinary').v2;
            const fs = require('fs');
            const https = require('https');
            const path = require('path');

            cloudinary.config({
              cloud_name: process.env.CLOUDINARY_CLOUD_NAME,
              api_key: process.env.CLOUDINARY_API_KEY,
              api_secret: process.env.CLOUDINARY_API_SECRET
            });

            async function downloadFile(url, filePath) {
              return new Promise((resolve, reject) => {
                const file = fs.createWriteStream(filePath);
                https.get(url, (res) => {
                  res.pipe(file);
                  file.on('finish', () => {
                    file.close();
                    resolve();
                  });
                }).on('error', (err) => {
                  fs.unlink(filePath, () => reject(err));
                });
              });
            }

            async function backupCloudinary() {
              try {
                const result = await new Promise((resolve, reject) => {
                  cloudinary.api.resources({ type: 'upload', max_results: 500 }, (err, result) => {
                    if (err) reject(err);
                    else resolve(result);
                  });
                });

                const downloadPromises = result.resources.map(async (r) => {
                  const url = r.secure_url;
                  const fileName = path.join('backup/cloudinary', r.public_id.replace(/\//g, '_') + '.' + r.format);
                  await downloadFile(url, fileName);
                });

                await Promise.all(downloadPromises);
                console.log('Cloudinary backup completed');
              } catch (err) {
                console.error('Cloudinary backup failed:', err);
                process.exit(1);
              }
            }

            backupCloudinary();
          "

      # --- Save .env ---
      - name: Save .env
        run: echo "$BACKEND_ENV" > backup/.env

      # --- Copy Code to Backup ---
      - name: Copy Code to Backup
        run: |
          cp -r backend backup/
          cp -r frontend backup/

      # --- Zip All Backups ---
      - name: Create ZIP
        run: |
          TIMESTAMP=$(date +'%F_%H-%M')
          zip -r full_backup_$TIMESTAMP.zip backup

      # --- Upload to Google Drive ---
      - name: Upload to Google Drive
        run: |
          pip install google-auth requests
          echo "$SERVICE_ACCOUNT_JSON" > service_account.json
          python3 << 'EOF'
          import json
          import google.auth.transport.requests
          from google.oauth2 import service_account
          import requests
          import glob
          import os

          # Load service account
          print('Loading service account...')
          with open('service_account.json') as f:
            service_account_json = f.read()
          service_account_info = json.loads(service_account_json)
          print('Service account loaded')
          credentials = service_account.Credentials.from_service_account_info(service_account_info, scopes=['https://www.googleapis.com/auth/drive.file'])
          request = google.auth.transport.requests.Request()
          print("Refreshing credentials...")
          credentials.refresh(request)
          access_token = credentials.token
          print("Access token obtained")

          # Find the backup file
          files = glob.glob('full_backup_*.zip')
          if not files:
            raise Exception('No backup file found')
          file_path = files[0]
          print('Found backup file: ' + file_path)

          # Upload to Google Drive
          folder_id = os.environ['GDRIVE_FOLDER_ID']
          print('Uploading to folder: ' + folder_id)
          metadata = {
            'name': os.path.basename(file_path),
            "driveId": folder_id
          }
          files_payload = {
            'data': ('metadata', json.dumps(metadata), 'application/json; charset=UTF-8'),
            'file': (os.path.basename(file_path), open(file_path, 'rb'), 'application/zip')
          }
          print("Sending upload request...")
          response = requests.post(
            "https://www.googleapis.com/upload/drive/v3/files?uploadType=multipart&supportsAllDrives=true",
            headers={'Authorization': "Bearer " + access_token},
            files=files_payload
          )
          print('Response status: ' + str(response.status_code))
          if response.status_code == 200:
            print('Upload successful')
            print('Response:', response.json())
          else:
            print('Upload failed: ' + str(response.status_code))
            print('Response:', response.text)
            exit(1)
          EOF